# infra-autofix-agent

[![CI Pipeline](https://github.com/mainulhossain123/infra-autofix-agent/actions/workflows/ci.yml/badge.svg)](https://github.com/mainulhossain123/infra-autofix-agent/actions/workflows/ci.yml)
[![Security Scanning](https://github.com/mainulhossain123/infra-autofix-agent/actions/workflows/security.yml/badge.svg)](https://github.com/mainulhossain123/infra-autofix-agent/actions/workflows/security.yml)
[![Docker Publish](https://github.com/mainulhossain123/infra-autofix-agent/actions/workflows/docker-publish.yml/badge.svg)](https://github.com/mainulhossain123/infra-autofix-agent/actions/workflows/docker-publish.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **AI-Powered Auto-Remediation Platform** with 6 production-ready ML models for predictive incident detection, automated root cause analysis, and intelligent self-healing infrastructure.

## âœ¨ Features

### Core Platform
- ğŸ” **Automated Incident Detection** - CPU spikes, memory leaks, high error rates, latency issues
- ğŸ”„ **Self-Healing** - Automatic container restarts with circuit breaker protection
- ğŸ“Š **Full Observability Stack** - Grafana dashboards, Prometheus metrics, Loki logs
- âš¡ **Real-time Updates** - WebSocket-based live dashboard
- ğŸš¨ **Smart Alerting** - Configurable thresholds with Prometheus alerts
- ğŸ³ **Cloud-Native** - Docker/Kubernetes ready with multi-platform support
- ğŸ” **Production-Grade** - CI/CD pipelines, security scanning, automated testing
- ğŸ“– **Interactive API Documentation** - Swagger UI with live testing at http://localhost:5000/api/docs

### ğŸ¤– AI/ML Capabilities (All 6 Phases Complete!)
- **Phase 2: Anomaly Detection** - Isolation Forest with 92-95% accuracy, <10ms inference
- **Phase 3: Time Series Forecasting** - Prophet models predict metrics 1-24 hours ahead
- **Phase 4: LLM Integration** - Ollama + Llama 3.2 for root cause analysis (100% free, local)
- **Phase 5: Failure Prediction** - LightGBM predicts system failures up to 72 hours ahead
- **Phase 6: Continuous Learning** - Automated model retraining and performance monitoring

**Result**: Proactive incident prevention with AI-powered insights and zero API costs!

## ğŸš€ Quick Start

> **ğŸ“˜ New to the project?** See the [Complete Quick Start Guide](docs/quick-start.md) with step-by-step instructions and screenshots.

### Prerequisites

- **Docker Compose**: Docker 20.10+, Docker Compose 2.0+
- **Kubernetes** (optional): kubectl, Helm 3.0+, K8s cluster 1.20+
- **ML Features** (optional): 4GB RAM for Ollama LLM service

### Option 1: Docker Compose (Recommended)

**Basic Setup:**
```bash
git clone https://github.com/mainulhossain123/infra-autofix-agent.git
cd infra-autofix-agent
docker compose up -d
```

**With ML/AI Features (Recommended):**
```bash
# Start with ML services (Ollama LLM + all AI features)
docker compose -f docker-compose.yml -f docker-compose.ml.yml up -d

# Download the LLM model (one-time setup, ~2GB)
docker exec -it ar_ollama ollama pull llama3.2:3b
```

**Access Services:**
- ğŸ¨ Dashboard: http://localhost:3000
- ğŸ“– Swagger API: http://localhost:5000/api/docs
- ğŸ“Š Grafana: http://localhost:3001 (admin/admin)
- ğŸ”§ Backend API: http://localhost:5000
- ğŸ“ˆ Prometheus: http://localhost:9090

### Option 2: Kubernetes (Production)

**With Helm:**
```bash
# Development
helm install infra-autofix ./helm/infra-autofix \
  --namespace infra-autofix-dev \
  --create-namespace \
  --values ./helm/infra-autofix/values-dev.yaml

# Production
helm install infra-autofix ./helm/infra-autofix \
  --namespace infra-autofix-prod \
  --create-namespace \
  --values ./helm/infra-autofix/values-prod.yaml
```

**With kubectl:**
```bash
kubectl apply -k k8s/

# Access services at (Docker Desktop):
# Dashboard: http://localhost
# Grafana: http://localhost:3000 (admin/admin)
# API: http://localhost:5000
```

**Or use deployment script:**
```bash
# PowerShell
.\scripts\deploy-k8s.ps1 -Method helm -Environment dev

# Bash
./scripts/deploy-k8s.sh helm dev
```

> **âš ï¸ Important**: Grafana dashboards need to be imported manually in Kubernetes. See [Quick Start Guide](docs/quick-start.md#6-configure-grafana-dashboards).

See [Kubernetes Deployment Guide](docs/kubernetes.md) for detailed instructions.

### Access Interfaces

**Docker Compose URLs:**

| Service | URL | Credentials | Notes |
|---------|-----|-------------|-------|
| ğŸ¨ **React Dashboard** | **http://localhost:3000** | - | **Main UI with ML insights** |
| ğŸ“– **Swagger API Docs** | **http://localhost:5000/api/docs** | - | **Interactive ML API testing** |
| ğŸ”§ Backend API | http://localhost:5000 | - | REST + WebSocket |
| ğŸ“Š Grafana | http://localhost:3001 | admin/admin | Dashboards & alerts |
| ğŸ“ˆ Prometheus | http://localhost:9090 | - | Metrics query UI |
| ğŸ“ Loki | http://localhost:3100 | - | Log aggregation |
| ğŸ¤– Ollama (LLM) | http://localhost:11434 | - | Local AI model API |

**ML/AI Feature Access:**
- **Dashboard UI**: http://localhost:3000 - View incidents with AI analysis, predictions, and anomaly scores
- **Swagger API**: http://localhost:5000/api/docs - Test all ML endpoints interactively
- **Direct API**: http://localhost:5000/api/ml/* - Programmatic access to ML features
  - `/api/ml/anomaly/*` - Anomaly detection
  - `/api/ml/forecast/*` - Time series predictions
  - `/api/ml/failure-prediction/*` - Failure forecasting
  - `/api/ml/analyze/*` - LLM incident analysis
  - `/api/ml/continuous-learning/*` - Model management

**Kubernetes URLs (Docker Desktop):**

| Service | URL | Credentials | Purpose |
|---------|-----|-------------|---------|
| ğŸ¨ **Dashboard** | **http://localhost** | - | **Main UI with ML insights** |
| ğŸ“– **Swagger API** | **http://localhost:5000/api/docs** | - | **Interactive ML API docs** |
| ğŸ”§ Backend API | http://localhost:5000 | - | REST API + WebSocket |
| ğŸ“Š Grafana | http://localhost:3000 | admin/admin | Monitoring dashboards |
| ğŸ“ˆ Prometheus | http://localhost:9090 | - | Metrics database |

> **ğŸ’¡ ML Features**: All AI/ML insights are **integrated into the main dashboard**. No separate ML UI needed - anomaly scores, predictions, and AI analysis are displayed directly in the incidents view!

## ğŸ—ï¸ Architecture

**Full System Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Interfaces                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¨ React Dashboard (3000)    â”‚  ğŸ“– Swagger API Docs (5000)    â”‚
â”‚  - Real-time monitoring        â”‚  - Interactive ML API testing  â”‚
â”‚  - AI insights display         â”‚  - All endpoints documented    â”‚
â”‚  - Incident management         â”‚  - Try ML features live        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                            â”‚
                 â–¼                            â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚         Flask API + ML Engine (5000)            â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
       â”‚  â”‚  REST API  â”‚  WebSocket  â”‚  ML Routes   â”‚   â”‚
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
       â”‚  â”‚          6 ML Models Pipeline            â”‚   â”‚
       â”‚  â”‚  Phase 2: Anomaly Detection (IForest)    â”‚   â”‚
       â”‚  â”‚  Phase 3: Time Series Forecast (Prophet) â”‚   â”‚
       â”‚  â”‚  Phase 4: LLM Analysis (Ollama)          â”‚   â”‚
       â”‚  â”‚  Phase 5: Failure Prediction (LightGBM)  â”‚   â”‚
       â”‚  â”‚  Phase 6: Continuous Learning            â”‚   â”‚
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                  â”‚                 â”‚
            â–¼                  â–¼                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  PostgreSQL    â”‚  â”‚   Ollama    â”‚  â”‚ Remediation  â”‚
   â”‚  Database      â”‚  â”‚ LLM Service â”‚  â”‚     Bot      â”‚
   â”‚  - Metrics     â”‚  â”‚ Llama 3.2   â”‚  â”‚ - Auto-heal  â”‚
   â”‚  - Incidents   â”‚  â”‚ (3B params) â”‚  â”‚ - ML checks  â”‚
   â”‚  - ML Data     â”‚  â”‚  Port 11434 â”‚  â”‚ - Retraining â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
            â”‚                                          â”‚
            â–¼                                          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Observability   â”‚                    â”‚   Container      â”‚
   â”‚  Stack           â”‚                    â”‚   Infrastructure â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ â€¢ Prometheus     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â€¢ App Containers â”‚
   â”‚ â€¢ Grafana        â”‚                    â”‚ â€¢ Docker/K8s     â”‚
   â”‚ â€¢ Loki + Promtailâ”‚                    â”‚ â€¢ Health Checks  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ML Pipeline Data Flow:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Metrics    â”‚â”€â”€â”€â”€â–¶â”‚ Feature Engineeringâ”‚â”€â”€â”€â”€â–¶â”‚  Anomaly Model  â”‚
â”‚  Collection  â”‚     â”‚   (100+ features)  â”‚     â”‚ (Isolation Tree)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Incident Created?   â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Yes    â”‚ No
                â–¼        â””â”€â”€â”€â”€â”€â–¶ Continue monitoring
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Parallel ML Tasks   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 1. Failure Predictor â”‚â”€â”€â–¶ Risk: High/Med/Low
    â”‚ 2. Time Series Fcst  â”‚â”€â”€â–¶ Breach in N hours
    â”‚ 3. LLM Analyzer      â”‚â”€â”€â–¶ Root cause + fixes
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Store Results  â”‚â”€â”€â”€â”€â”€â–¶â”‚  Display in UI   â”‚
    â”‚  in Database    â”‚      â”‚  & Send Alerts   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Continuous Learning â”‚
    â”‚ - Track performance â”‚
    â”‚ - Auto-retrain      â”‚
    â”‚ - Model versioning  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤– ML/AI Features Deep Dive
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Prometheusâ”‚ â”‚ Grafana  â”‚  â”‚   Loki   â”‚
â”‚  :9090   â”‚ â”‚  :3001   â”‚  â”‚  :3100   â”‚
```

## ğŸ¤– ML/AI Features Deep Dive

> **ğŸ¨ Access ML Features**: All AI insights are integrated into the **main dashboard** at http://localhost:3000. View anomaly scores, predictions, and AI analysis directly in the incidents view. For programmatic access, use the **Swagger UI** at http://localhost:5000/api/docs to test all ML endpoints interactively.

### Phase 2: Anomaly Detection
- **Algorithm**: Isolation Forest
- **Features**: 100+ engineered metrics
- **Performance**: 92-95% accuracy, <10ms inference
- **Triggers**: Automatic incident creation for ML-detected anomalies
- **UI**: Anomaly scores shown in dashboard incident cards
- **API**: `POST /api/ml/anomaly/train`, `POST /api/ml/anomaly/predict`
- **Test**: `.\scripts\test-phase2.ps1`

### Phase 3: Time Series Forecasting
- **Algorithm**: Facebook Prophet
- **Capabilities**: 1-24 hour ahead predictions
- **Features**: Daily/weekly seasonality detection
- **Use Case**: Proactive breach detection before thresholds hit
- **UI**: Predicted values displayed in metrics charts
- **API**: `POST /api/ml/forecast/train`, `GET /api/ml/forecast/predict`
- **Test**: `.\scripts\test-phase3.ps1`

### Phase 4: LLM Integration
- **Model**: Ollama + Llama 3.2 (3B parameters)
- **Cost**: 100% free (runs locally)
- **Features**: Root cause analysis, natural language reports, remediation suggestions
- **Requirements**: 4GB RAM, ~2GB model download
- **UI**: AI-generated insights shown in incident details
- **API**: `POST /api/ml/analyze/incident/<id>`, `GET /api/ml/generate-report/<id>`
- **Health Check**: `GET /api/ml/llm/health`
- **Setup**: `docker exec -it ar_ollama ollama pull llama3.2:3b`
- **Test**: `.\scripts\test-phase4.ps1`

### Phase 5: Failure Prediction
- **Algorithm**: LightGBM (gradient boosting)
- **Prediction Window**: 1-72 hours ahead
- **Risk Levels**: High (70%+), Medium (40-70%), Low (<40%)
- **Proactive Alerts**: Creates "predicted_failure" incidents
- **UI**: Risk indicators and predictions in dashboard alerts
- **API**: `POST /api/ml/failure-prediction/train`, `POST /api/ml/failure-prediction/predict`
- **Test**: `.\scripts\test-phase5.ps1`

### Phase 6: Continuous Learning
- **Auto-Retraining**: Every 24 hours or when 100+ new samples collected
- **Performance Monitoring**: Tracks accuracy, precision, MAE
- **Model Versioning**: Full training history in database
- **Triggers**: Time-based, data-volume, performance degradation
- **UI**: Model status and retraining history in config page (future enhancement)
- **API**: `GET /api/ml/continuous-learning/status`, `POST /api/ml/continuous-learning/check-retrain`
- **Test**: `.\scripts\test-phase6.ps1`

### How to Access ML Features

**1. Main Dashboard (http://localhost:3000)**
- View incidents with anomaly scores
- See AI-generated root cause analysis
- Monitor predicted failures
- Check risk indicators

**2. Swagger API (http://localhost:5000/api/docs)**
- Interactive ML endpoint testing
- Try predictions with custom data
- Explore all ML API capabilities
- View request/response schemas

**3. Grafana Dashboards (http://localhost:3001)**
- ML model performance metrics
- Prediction accuracy over time
- Model retraining history
- Anomaly detection rates

**4. Direct API Calls**
```bash
# Check ML system status
curl http://localhost:5000/api/ml/continuous-learning/status

# Get incident AI analysis
curl http://localhost:5000/api/ml/analyze/incident/1

# Check LLM health
curl http://localhost:5000/api/ml/llm/health

# Predict next hour failures
curl -X POST http://localhost:5000/api/ml/failure-prediction/predict
```

**Quick ML Setup:**
```bash
# Start with ML services
docker compose -f docker-compose.yml -f docker-compose.ml.yml up -d

# Download LLM model (one-time)
docker exec -it ar_ollama ollama pull llama3.2:3b

# Check ML system status
curl http://localhost:5000/api/ml/continuous-learning/status

# Run ML test scripts
.\scripts\test-phase4.ps1  # LLM integration
.\scripts\test-phase5.ps1  # Failure prediction
.\scripts\test-phase6.ps1  # Continuous learning
```

See [ML Setup Guide](docs/ml-setup.md) for complete documentation.

## Deployment Options

### ğŸ³ Docker Compose (Local/Development)
Single-command setup for local development and testing. All services run in containers with Docker networking.

```bash
docker compose up -d
```

### â˜¸ï¸ Kubernetes (Production/Cloud)
Enterprise-grade deployment with auto-scaling, health checks, and high availability.

- **Raw Manifests**: Full control with `kubectl apply -k k8s/`
- **Helm Charts**: Environment management with `helm install`
- **Kustomize**: Overlay-based configuration

Features:
- Horizontal Pod Autoscaling (2-10 replicas)
- Persistent volumes for databases
- RBAC and service accounts
- LoadBalancers and Ingress
- Multi-environment support (dev/staging/prod)

See [Kubernetes Guide](docs/kubernetes.md) for full deployment instructions.

---

## Development

### Local Setup (Without Docker)

**Backend:**
```powershell
cd app
py -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
python app.py
```

**Bot:**
```powershell
cd bot
py -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
python bot.py
```

**Frontend:**
```powershell
cd frontend
npm install
npm run dev  # http://localhost:5173
```

### Testing

```powershell
# Backend
cd app
pytest tests/ --cov

# Linting
flake8 app bot

# Frontend
cd frontend
npm run build
```

## ğŸ“Š Monitoring & Observability

### Grafana Dashboards
Access at http://localhost:3001 (Docker) or http://localhost:3000 (K8s) with `admin/admin`

**Pre-built Dashboards:**
- **System Overview** - Real-time health, incidents, remediation success rate
- **Application Metrics** - Request rates, latency, error rates by service
- **Infrastructure** - CPU, memory, disk usage across all containers
- **Incident Analysis** - Incident types, frequency, MTTR (Mean Time To Remediation)
- **ML Performance** - Model accuracy, predictions, retraining history

### Prometheus Metrics
Query at http://localhost:9090

**Key Metrics:**
- `http_requests_total` - Total HTTP requests
- `http_request_duration_seconds` - Request latency
- `incidents_total` - Total incidents by type and severity
- `remediations_total` - Successful/failed remediations
- `container_cpu_usage_seconds_total` - Container CPU usage
- `ml_predictions_total` - ML model predictions
- `ml_model_accuracy` - Model performance metrics

### Loki Logs
Access at http://localhost:3100 or via Grafana Explore

**Log Labels:**
- `{container="ar_app"}` - Flask API logs
- `{container="ar_bot"}` - Remediation bot logs
- `{container="ar_frontend"}` - React UI logs

### Alerts
Pre-configured Prometheus alerts in `prometheus/alerts.yml`:
- High error rate (>5% errors)
- Latency spike (p95 > 500ms)
- Resource exhaustion (CPU >90%, Memory >85%)
- Incident rate spike (>10 incidents/5min)

See [Observability Guide](docs/observability.md) for detailed monitoring setup.

## Automation

Includes 7 GitHub Actions workflows for CI/CD:
- **CI** - Testing, linting, building
- **Docker Publish** - GHCR image publishing with semantic versioning
- **Security** - CodeQL, Trivy, dependency scanning
- **Deploy** - AWS ECS and VM deployment
- **Performance** - Locust load testing
- **Release** - Automated GitHub releases
- **Cleanup** - Artifact management

See [docs/github-actions.md](docs/github-actions.md) for details.

## ğŸ“š Documentation

### Essential Guides
- ğŸš€ **[Quick Start Guide](docs/quick-start.md)** - Complete setup for Docker Compose and Kubernetes
- ğŸ¤– **[ML Setup Guide](docs/ml-setup.md)** - All 6 ML phases with examples and API references
- ğŸ“– **[API Reference](docs/API.md)** - REST endpoints, WebSocket events, request/response formats
- â˜¸ï¸ **[Kubernetes Guide](docs/kubernetes.md)** - Production deployment with Helm charts

### Operations
- ğŸ”§ **[Operations Guide](docs/operations.md)** - Configuration, testing, troubleshooting
- ğŸ“Š **[Observability](docs/observability.md)** - Metrics, dashboards, alerts, logging
- ğŸ³ **[Docker Commands](docs/docker.md)** - Container management reference

### Automation
- ğŸš€ **[GitHub Actions](docs/github-actions.md)** - CI/CD workflows and deployment

### API Documentation (Interactive)
- ğŸ“– **Swagger UI**: http://localhost:5000/api/docs (Docker Compose)
- ğŸ“– **Swagger UI**: http://localhost:5000/api/docs (Kubernetes)

**Key API Endpoints:**
- **Core**: `/api/health`, `/api/incidents`, `/api/metrics`, `/api/config`
- **ML Phase 2**: `/api/ml/anomaly/*` - Anomaly detection
- **ML Phase 3**: `/api/ml/forecast/*` - Time series forecasting
- **ML Phase 4**: `/api/ml/analyze/*`, `/api/ml/llm/*` - LLM analysis
- **ML Phase 5**: `/api/ml/failure-prediction/*` - Failure prediction
- **ML Phase 6**: `/api/ml/continuous-learning/*` - Model management

## ğŸ”— Important URLs

### Local Development (Docker Compose)
```
Main Dashboard:        http://localhost:3000
Swagger API Docs:      http://localhost:5000/api/docs
REST API:              http://localhost:5000/api/*
WebSocket:             ws://localhost:5000/ws
Grafana:               http://localhost:3001
Prometheus:            http://localhost:9090
Loki:                  http://localhost:3100
Ollama LLM:            http://localhost:11434
```

### Kubernetes (Docker Desktop)
```
Main Dashboard:        http://localhost
Swagger API Docs:      http://localhost:5000/api/docs
REST API:              http://localhost:5000/api/*
Grafana:               http://localhost:3000
Prometheus:            http://localhost:9090
```

### GitHub Repository
```
Source Code:           https://github.com/mainulhossain123/infra-autofix-agent
CI Pipeline:           https://github.com/mainulhossain123/infra-autofix-agent/actions
Container Registry:    ghcr.io/mainulhossain123/infra-autofix-agent
Issues:                https://github.com/mainulhossain123/infra-autofix-agent/issues
```

## License

MIT Â© 2025
